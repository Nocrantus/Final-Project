{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb42e2ae-fc0c-4875-91c5-ab3146628d58",
   "metadata": {},
   "source": [
    "# Interactive Data Visualization\n",
    "##### (C) 2023-2025 Timothy James Becker: [revision 1.0](),  [GPLv3 license](https://www.gnu.org/licenses/gpl-3.0.html) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4da184-91f4-452a-995d-5e24a68a103e",
   "metadata": {},
   "source": [
    "#### <u>Missingness in Data</u>\n",
    "\n",
    "Data has missing values when looking at multiple columns such as the NHANES 2018 data used in [07_Data_Cleaning.ipynb]. But upon closer inspection data is missing for different reasons. It could be missing based on some random process that has corrupted the data, it could be missing because someone was embarrassed about the survey question, it could be missing because of data privacy issues.  Let look more formally at the type of missing values or the missingness of the data below. There is a nice MICE video [here](https://www.youtube.com/watch?v=WPiYOS3qK70)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7381364-41bd-420a-83cb-22397f85a862",
   "metadata": {},
   "source": [
    "##### <b>Missing Completely at Random MCAR</b>\n",
    "When a missing value is encountered in a column but it cannot be predicted by any other column of data (IE it is completely independent from all other columns of data). We say this is missing completely at random or [MCAR](https://stefvanbuuren.name/fimd/sec-MCAR.html).\n",
    "\n",
    "##### <b>Missing at Random (MAR)</b>\n",
    "When the missing value has some dependency with one or more of the other columns of data in which case its value is associated with the other values (IE the other values can predict more than background the value of a missing value in this column).  We say this is missing at random or [MAR](https://stefvanbuuren.name/fimd/sec-MCAR.html).\n",
    "\n",
    "##### <b>Missing not-at random (MNAR)</b>\n",
    "When the missing value was removed for privacy issues or some specific reason like they were embarrassed. We say this is missing not at random or [MNAR](https://stefvanbuuren.name/fimd/sec-MCAR.html).\n",
    "\n",
    "\n",
    "##### <b>Which one can we try to estimate? </b>\n",
    "We will see that [MAR](https://stefvanbuuren.name/fimd/sec-MCAR.html) is the type of missingness that can be estimated well by methods such as multi-variate imputation by chained equations [MICE](https://github.com/amices/mice?tab=readme-ov-file)\n",
    "\n",
    "<img src=\"figures/data_imputation_overview.png\" alt=\"data_imputation_overview\" width=\"700px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1394387-5b3f-454b-8fd1-bdfad3cc422f",
   "metadata": {},
   "source": [
    "#### <u>Missing Data I (remove)</u>\n",
    "We discussed one simple method is to remove data (after projection in order to lose less). Letâ€™s use our NHANES data and remove any row that has at least one missing value. Then we will project first and then remove and explore how much of the 10,000 rows of data we lose in this filtering process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b122b5f-c019-4631-af84-ef6a06987d99",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#[Load and Process the Dataset: NHANES-10000]\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgzip\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\pyplot.py:57\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcycler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cycler  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolorbar\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _api\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\colorbar.py:19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _api, cbook, collections, cm, colors, contour, ticker\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01martist\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmartist\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpatches\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmpatches\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\contour.py:15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _api, _docstring\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MouseButton\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlines\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Line2D\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\backend_bases.py:49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m     _api, backend_tools \u001b[38;5;28;01mas\u001b[39;00m tools, cbook, colors, _docstring, text,\n\u001b[0;32m     51\u001b[0m     _tight_bbox, transforms, widgets, is_interactive, rcParams)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pylab_helpers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Gcf\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ToolManager\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1322\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1262\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1559\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1533\u001b[0m, in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1632\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:152\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#[Load and Process the Dataset: NHANES-10000]\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import gzip\n",
    "with gzip.GzipFile('Covid.csv.gz','rb') as f:\n",
    "    #gp from raw data into filtered and clean data--------------------------------------------------\n",
    "    raw = [row.decode('utf-8').replace('\\n','').replace('\\r','').split(',') for row in f.readlines()]\n",
    "    header,data = raw[0],raw[1:]\n",
    "idx = {header[i]:i for i in range(len(header))} #build the dictionary so we can select columns by name\n",
    "print(header)\n",
    "print(len(data))\n",
    "print(len(header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08607f84-418b-43b0-8e52-1b0e83bafcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = sorted(header) #we will revise this cell to project the cols we want\n",
    "cols[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aa8b96-8911-4bf6-a64b-01d64c3f9957",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = []\n",
    "for d in data:\n",
    "    row = [d[idx[e]] for e in cols]     #pick the cols we want and clear the rest\n",
    "    if not any([e=='NA' for e in row]): #this row is good\n",
    "        clean += [row]                  #add it to our dataset\n",
    "print('We have %s out of %s rows'%(len(clean),len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8768b0-7656-461f-ba65-28a3aded689d",
   "metadata": {},
   "source": [
    "Zero rows is not great for visualization! Lets now project the rows we want and then filter them to see what we have left:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15650a52-36ff-43c2-af2c-7bca30f5bc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Age','BMI','Gender','Diabetes','HardDrugs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa506f3-2bea-4f5b-adcd-96c6e885b12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = []\n",
    "for d in data:\n",
    "    row = [d[idx[e]] for e in cols]     #pick the cols we want and clear the rest\n",
    "    if not any([e=='NA' for e in row]): #this row is good\n",
    "        clean += [row]                  #add it to our dataset\n",
    "print('We have %s out of %s rows'%(len(clean),len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db12029-cf32-4c19-99f2-b42bbb9d58a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(set([e[idx['Diabetes']] for e in data]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fffc7df-bfee-4e86-aca4-2e9b6492663c",
   "metadata": {},
   "source": [
    "This is much better and now we have 5732 complete rows of data which means we lost around half of the data. Which cols do you think are MAR? Which ones are MNAR?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bde871-a5c8-410c-aa8e-9e162211f5a3",
   "metadata": {},
   "source": [
    "#### <u>Missing Data II (estimate badly)</u>\n",
    "If we have some rows we think are MAR we can try to estimate the values using basic univariate methods which are actually not very good. But they will help use to understand the multivariate methods even though they are technically a type of predictive model! If we take a specific column and build its histogram as we have done in [07_Data_Cleaning.ipynb] we can sample from that distribution effectively thereby coming up with a reasonable univariate estimate. Before we do that lets instead use an even worse estimate that may be your first idea: take the mean or mode of the column and use that as an estimate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2aeadf-2e25-482d-b238-01be90a9516b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#covert our data to numeric by either using if/else or by using a dictionary to map values to numbers\n",
    "import re\n",
    "age_data = [(float(e[idx['Age']]) if e[idx['Age']].isdecimal() else np.nan) for e in data]\n",
    "bmi_data = [(float(e[idx['BMI']]) if re.match(r'^-?\\d+(?:\\.\\d+)$', e[idx['BMI']]) is not None else np.nan) for e in data]\n",
    "gen = {'female':0,'male':1,'NA':np.nan}\n",
    "gen_data = [gen[e[idx['Gender']]] for e in data]\n",
    "dia = {'Yes':1,'No':0,'NA':np.nan}\n",
    "dia_data = [dia[e[idx['Diabetes']]] for e in data]\n",
    "hard = {'Yes':1,'No':0,'NA':np.nan}\n",
    "hard_data = [hard[e[idx['HardDrugs']]] for e in data]\n",
    "age_data[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a082d857-9a75-482c-b0c2-e83631504f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets do some bad univariate estimating: the mean of the non-missing values\n",
    "age_data = np.asarray(age_data)\n",
    "age_data[np.isnan(age_data)] = np.mean(age_data[~np.isnan(age_data)]) #we put the mean where we see nan\n",
    "\n",
    "bmi_data = np.asarray(bmi_data)\n",
    "bmi_data[np.isnan(bmi_data)] = np.mean(bmi_data[~np.isnan(bmi_data)])\n",
    "\n",
    "gen_data = np.asarray(gen_data)\n",
    "gen_data[np.isnan(gen_data)] = np.mean(gen_data[~np.isnan(gen_data)])\n",
    "\n",
    "dia_data = np.asarray(dia_data)\n",
    "dia_data[np.isnan(dia_data)] = np.mean(dia_data[~np.isnan(dia_data)])\n",
    "\n",
    "hard_data = np.asarray(hard_data)\n",
    "hard_data[np.isnan(hard_data)] = np.mean(hard_data[~np.isnan(hard_data)])\n",
    "\n",
    "#glue all the data back together now\n",
    "n = len(age_data)\n",
    "new_data = np.concatenate([age_data.reshape(n,1),bmi_data.reshape(n,1),\n",
    "                           gen_data.reshape(n,1),dia_data.reshape(n,1),\n",
    "                           hard_data.reshape(n,1)],axis=1)\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995b04c1-0e07-401a-8f3a-8a20367e2259",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(bmi_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1360064b-245e-42ff-a0be-3f9b31a6420a",
   "metadata": {},
   "source": [
    "Because we supplied the mean of the non-missing values, we will end up with a final dataset that will have a similar mean for each column. But what will happen when we visualize that? It looks like the mean value get over represented which changes the distribution of your data. This means visualization will be terrible..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbee8a1-9707-491c-b1fc-45fc0919165c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the empirical univariate distribution to estiamte each value\n",
    "age_data = [(float(e[idx['Age']]) if e[idx['Age']].isdecimal() else np.nan) for e in data]\n",
    "bmi_data = [(float(e[idx['BMI']]) if re.match(r'^-?\\d+(?:\\.\\d+)$', e[idx['BMI']]) is not None else np.nan) for e in data]\n",
    "gen = {'female':0,'male':1,'NA':np.nan}\n",
    "gen_data = [gen[e[idx['Gender']]] for e in data]\n",
    "dia = {'Yes':1,'No':0,'NA':np.nan}\n",
    "dia_data = [dia[e[idx['Diabetes']]] for e in data]\n",
    "hard = {'Yes':1,'No':0,'NA':np.nan}\n",
    "hard_data = [hard[e[idx['HardDrugs']]] for e in data]\n",
    "age_data[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f86f900-3360-48ad-a215-e1068ce794eb",
   "metadata": {},
   "source": [
    "Here we are now going to be a empirical distribution for each column (univariate estimate) then we will sample from this distribution when it comes time to pick a value when NA is encountered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880c90b2-9eb7-4d77-a882-1a7ce2d30605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_est(col_data):\n",
    "    n = len(col_data)                       #original data size\n",
    "    col_data = np.asarray(col_data)         #make sure it is a numpy array so we can find nan\n",
    "    col_in = col_data[~np.isnan(col_data)]  #grab the non-nan values\n",
    "    m = len(col_in)                         #how many values are present in the non-nan data?\n",
    "    hist = {}                               #build up a histogram and total counts to make the prob distribution\n",
    "    for e in col_in:                        #histogram counts every value\n",
    "        if e not in hist: hist[e]  = 1/m    #and divides by total number\n",
    "        else:             hist[e] += 1/m    #to produce the empircial distribution\n",
    "    est = np.random.choice([h for h in hist],n-m,replace=True,p=[hist[h] for h in hist])\n",
    "    return est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83683655-fad1-41c1-8f5e-9f84b6e935f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_data = np.asarray(age_data)\n",
    "age_data[np.isnan(age_data)] = get_est(age_data)\n",
    "\n",
    "bmi_data = np.asarray(bmi_data)\n",
    "bmi_data[np.isnan(bmi_data)] = get_est(bmi_data)\n",
    "\n",
    "gen_data = np.asarray(gen_data)\n",
    "gen_data[np.isnan(gen_data)] = get_est(gen_data)\n",
    "\n",
    "dia_data = np.asarray(dia_data)\n",
    "dia_data[np.isnan(dia_data)] = get_est(dia_data)\n",
    "\n",
    "hard_data = np.asarray(hard_data)\n",
    "hard_data[np.isnan(hard_data)] = get_est(hard_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b8a74b-edfe-4332-ab59-f96f6a495a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(age_data)\n",
    "new_data = np.concatenate([age_data.reshape(n,1),bmi_data.reshape(n,1),\n",
    "                           gen_data.reshape(n,1),dia_data.reshape(n,1),\n",
    "                           hard_data.reshape(n,1)],axis=1)\n",
    "print(new_data,new_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b042969-1c7e-4495-8e50-8853e4589d3a",
   "metadata": {},
   "source": [
    "This has the advantage of now having all 10,000 rows of data but we will have the correct empirical distribution instead of a single mean value being blasted on more than 1K rows which would change the distribution of each column but not the mean of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313527c0-7495-42f6-9d1e-e1338e02a3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(bmi_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa509647-4c89-49ce-bc10-f35a5ff4b533",
   "metadata": {},
   "source": [
    "Notice how this distribution is more accurate and the previous mean estimate which actually changes the distribution..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ecabd9-260c-47b4-99de-7f7e335ce4f8",
   "metadata": {},
   "source": [
    "#### <u>Data Imputation (estimate well)</u>\n",
    "Finally we can work to put together a better estimate. First, we will explore how some variables many depend on each other to determine if the MAR principle applies. Then we will make use of multivariate imputation by chained equations [MICE](https://www.youtube.com/watch?v=WPiYOS3qK70) which will do a much better job at estimating missing values (without changing distributions).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ddba45-1bb8-4cce-807b-8ea7f2ac40a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04b2ba2-c0bb-42fa-b92a-25075f1b65df",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_data = [(float(e[idx['Age']]) if e[idx['Age']].isdecimal() else np.nan) for e in data]\n",
    "bmi_data = [(float(e[idx['BMI']]) if re.match(r'^-?\\d+(?:\\.\\d+)$', e[idx['BMI']]) is not None else np.nan) for e in data]\n",
    "gen = {'female':0,'male':1,'NA':np.nan}\n",
    "gen_data = [gen[e[idx['Gender']]] for e in data]\n",
    "dia = {'Yes':1,'No':0,'NA':np.nan}\n",
    "dia_data = [dia[e[idx['Diabetes']]] for e in data]\n",
    "hard = {'Yes':1,'No':0,'NA':np.nan}\n",
    "hard_data = [hard[e[idx['HardDrugs']]] for e in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3dbbba-be4a-4313-96a9-632d7fe5fdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_data = np.asarray(age_data)\n",
    "bmi_data = np.asarray(bmi_data)\n",
    "gen_data = np.asarray(gen_data)\n",
    "dia_data = np.asarray(dia_data)\n",
    "hard_data = np.asarray(hard_data)\n",
    "n = len(age_data)\n",
    "D = np.concatenate([age_data.reshape(n,1),bmi_data.reshape(n,1),\n",
    "                    gen_data.reshape(n,1),dia_data.reshape(n,1),\n",
    "                    hard_data.reshape(n,1)],axis=1)\n",
    "print(D,D.shape) #this will have the nan which will will use MICE to fill in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679e201b-b770-42c8-aee4-648aee97e7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = IterativeImputer(max_iter=20,random_state=0) #this MICE\n",
    "imp.fit(D)\n",
    "X = imp.transform(D)\n",
    "X #no more nan values..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d180783-0b82-42d2-88c4-4609ef3fbd07",
   "metadata": {},
   "source": [
    "Since we had to convert to numeric values for MICE to work, we will have to map our values back into the regular ranges if we want to make our imputed NHANES file as nice as the original. Categorical data specifically will need some inverse mapping. For example, if we originally encoded 'female' as 0 and 'male' as 1 then it may make sense to round the values from 0 to 1 so that they will go back to 'female' and 'male'. That is to say you have to deal with fractional categorical values and rounding is one way to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51d42716-2d93-4ac3-a5f3-83daa233616f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'D' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m hard_m \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m0\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m1\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYes\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[0;32m      4\u001b[0m imp_data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(D)):\n\u001b[0;32m      6\u001b[0m     imp_row \u001b[38;5;241m=\u001b[39m [X[i][\u001b[38;5;241m0\u001b[39m],(\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m X[i][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m==\u001b[39mD[i][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m      7\u001b[0m                X[i][\u001b[38;5;241m1\u001b[39m],(\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m X[i][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m==\u001b[39mD[i][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m      8\u001b[0m                gen_m[\u001b[38;5;28mround\u001b[39m(X[i][\u001b[38;5;241m2\u001b[39m])],(\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m X[i][\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m==\u001b[39mD[i][\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m      9\u001b[0m                dia_m[\u001b[38;5;28mround\u001b[39m(X[i][\u001b[38;5;241m3\u001b[39m])],(\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m X[i][\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m==\u001b[39mD[i][\u001b[38;5;241m3\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     10\u001b[0m                hard_m[\u001b[38;5;28mround\u001b[39m(X[i][\u001b[38;5;241m4\u001b[39m])],(\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m X[i][\u001b[38;5;241m4\u001b[39m]\u001b[38;5;241m==\u001b[39mD[i][\u001b[38;5;241m4\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m     11\u001b[0m     imp_data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [imp_row]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'D' is not defined"
     ]
    }
   ],
   "source": [
    "gen_m  = {0:'female',1:'male'}\n",
    "dia_m  = {0:'No',1:'Yes'}\n",
    "hard_m = {0:'No',1:'Yes'}\n",
    "imp_data = []\n",
    "for i in range(len(D)):\n",
    "    imp_row = [X[i][0],(0 if X[i][0]==D[i][0] else 1),\n",
    "               X[i][1],(0 if X[i][1]==D[i][1] else 1),\n",
    "               gen_m[round(X[i][2])],(0 if X[i][2]==D[i][2] else 1),\n",
    "               dia_m[round(X[i][3])],(0 if X[i][3]==D[i][3] else 1),\n",
    "               hard_m[round(X[i][4])],(0 if X[i][4]==D[i][4] else 1)]\n",
    "    imp_data += [imp_row]\n",
    "imp_data[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15effac9-7f72-4645-96f3-1e6de22910c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pack it up as a new file we now know exactly which values have been imputed :)\n",
    "s = ','.join(['Age','Age_imp','BMI','BMI_imp','Gender','Gender_imp',\n",
    "              'Diabetes','Diabetes_imp','HardDrugs','HardDrugs_imp'])+'\\n'\n",
    "s += '\\n'.join([','.join([str(x) for x in row]) for row in imp_data])+'\\n'\n",
    "with open('nhanes.imp.csv','w') as f: f.write(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae34afe2-8ae7-4507-8b5d-2819e7a26541",
   "metadata": {},
   "source": [
    "#### <u>Intuition on how and why MICE works well</u>\n",
    "\n",
    "When columns move in a similar manner they are associated which is known as correlation. If we have a column x and a column y we can write it as:\n",
    "\n",
    "$r_{xy} = \\displaystyle\\frac{\\sum_{i=1}^{n} (x_i-\\bar{x})(y_i-\\bar{y}) }{\\sqrt{ \\sum_{i=1}^{n}(x_i-\\bar{x})^2 \\sum_{i=1}^{n}(y_i-\\bar{y})^2}} = \n",
    "\\frac{\\sum_{i=1}^{n} (x_i-\\bar{x})(y_i-\\bar{y}) }{(n-1) \\sqrt{ s_x^2 s_y^2 }}\n",
    "$\n",
    "\n",
    "The bar terms are the mean of those columns. If we are close to zero the two columns are basically independant and they don't need to be processed together with MICE. On the other hand, if they are close to -1 or 1 they are entirely dependant or associated and they should be jointly utilized in MICE. The in between range is also useful since it represents some minor association.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83fb258-6de1-40e2-ad3a-4791277b6ba8",
   "metadata": {},
   "source": [
    "We can calculate these values in our data using numpy/scipy/scikit-learn and also plot each column pair which is known as pair-wise correlation plots. Here we will show how to check and plot one pair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f527b6f-58e6-45f5-92c7-47d633c3580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_data = np.asarray(age_data)\n",
    "age_idx  = ~np.isnan(age_data)\n",
    "\n",
    "bmi_data = np.asarray(bmi_data)\n",
    "bmi_idx  = ~np.isnan(bmi_data)\n",
    "\n",
    "corr_idx = np.logical_and(age_idx,bmi_idx)\n",
    "age_in   = age_data[corr_idx]\n",
    "bmi_in   = bmi_data[corr_idx]\n",
    "\n",
    "corr = np.corrcoef(age_in,bmi_in)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.matshow(corr, cmap='viridis')\n",
    "for (i, j), z in np.ndenumerate(corr):\n",
    "    ax.text(j, i, '{:0.1f}'.format(z), ha='center', va='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6147a5a2-dcd7-4a7b-b53b-baf19382e3da",
   "metadata": {},
   "source": [
    "If we have non-zero correlation then we can build general linear models and use then iteratively to estimate (predict) the missing values that we encounter. In the example above we have 0.4 which is high enough that MICE will help and improve the univariate analysis we previously did.  This is the basic MICE premise but more in-depth discussion can be found in this [paper](https://pmc.ncbi.nlm.nih.gov/articles/PMC3074241/pdf/MPR-20-40.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe20969-78d2-4bff-b2f7-b1ec0f8a9676",
   "metadata": {},
   "source": [
    "#### Exercises\n",
    "#### [1] Using the new nhanes.imp.csv try to complete a scatter plot with any two columns as x and y\n",
    "#### [2] try to make a visual mark if your plotted circle is imputed either by making them a different shape or changing the color to visually indicate that imputation is being used.\n",
    "#### [3*] using the code supplied in this notebook pick additional columns of data that were not shown and produce the final MICE imputed file\n",
    "#### [4*] complete a visualization of your selected columns in part [3*] and make a visual indicator of any imputed values as required in [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a6db5a-620d-4153-be20-a7f322987a21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
